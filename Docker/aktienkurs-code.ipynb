{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datentypen, Dimension, Seperators checken bei Bereinigung (manuel), ob Werte auch die, die wir erwarten.\n",
    "EDA alles was nicht Modellierung und Statistisch ist. nur Histogramm, Boxplot etc. Mindestens 2 (z.b: Limeplot. werte Range mit Boxplot etc. Pairplot, Zeitlicher Lag von Closing/Opening Prises, Volumen, Volumen-Preis skettered Plot correlation). Also nur Explorative Datenanalyse für Verständnis und Hypothesen erstellen kann.\n",
    "Modell: Erweitertest Framework nehmen für Zusatzpunkte. Gäbe noch  nn => Nochmals prüfen. Was steckt dahinter? Pytorch wäre eine Option oder Lstm (Long short term memory network) \n",
    "Müssen wissen, welches NN verwendet wird => kommentieren (Torch.nn)\n",
    "7: Regression r^2 etc. \n",
    "classification wäre confusion matrix. Wir haben Regressionproblem, RMSE, MAPE (sicher dazu nehmen)\n",
    "Kreativitätspunkt: Technische Analyse einbauen."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Datenerhebung mittels API & Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import time\n",
    "import datetime\n",
    "from pandas_datareader import data\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Yahoo Finance API: Aktienkurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date        Open        High         Low       Close   Adj Close  \\\n",
      "0     2010-01-04    7.622500    7.660714    7.585000    7.643214    6.505281   \n",
      "1     2010-01-05    7.664286    7.699643    7.616071    7.656429    6.516526   \n",
      "2     2010-01-06    7.656429    7.686786    7.526786    7.534643    6.412872   \n",
      "3     2010-01-07    7.562500    7.571429    7.466071    7.520714    6.401018   \n",
      "4     2010-01-08    7.510714    7.571429    7.466429    7.570714    6.443574   \n",
      "...          ...         ...         ...         ...         ...         ...   \n",
      "3037  2022-01-26  163.500000  164.389999  157.820007  159.690002  158.526489   \n",
      "3038  2022-01-27  162.449997  163.839996  158.279999  159.220001  158.059906   \n",
      "3039  2022-01-28  165.710007  170.350006  162.800003  170.330002  169.088959   \n",
      "3040  2022-01-31  170.160004  175.000000  169.509995  174.779999  173.506546   \n",
      "3041  2022-02-01  174.009995  174.839996  172.309998  174.610001  173.337799   \n",
      "\n",
      "         Volume  \n",
      "0     493729600  \n",
      "1     601904800  \n",
      "2     552160000  \n",
      "3     477131200  \n",
      "4     447610800  \n",
      "...         ...  \n",
      "3037  108275300  \n",
      "3038  121954600  \n",
      "3039  179935700  \n",
      "3040  115541600  \n",
      "3041   86213900  \n",
      "\n",
      "[3042 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# Get Ticket Quotes from Yahoo Finance\n",
    "ticker = 'AAPL'\n",
    "period1 = int(time.mktime(datetime.datetime(2010, 1, 1, 23, 59).timetuple()))\n",
    "period2 = int(time.mktime(datetime.datetime(2022, 2, 1, 23, 59).timetuple()))\n",
    "interval = '1d'\n",
    "query_string = f'https://query1.finance.yahoo.com/v7/finance/download/{ticker}?period1={period1}&period2={period2}&interval={interval}&events=history&includeAdjustedClose=true'\n",
    "data = pd.read_csv(query_string)\n",
    "\n",
    "# Save data to a CSV file\n",
    "data.to_csv('AAPL Prices.csv')\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing page : 1\n",
      "https://www.politifact.com/factchecks/list/?page=1\n",
      "30\n",
      "processing page : 2\n",
      "https://www.politifact.com/factchecks/list/?page=2\n",
      "30\n",
      "processing page : 3\n",
      "https://www.politifact.com/factchecks/list/?page=3\n",
      "30\n",
      "processing page : 4\n",
      "https://www.politifact.com/factchecks/list/?page=4\n",
      "30\n",
      "processing page : 5\n",
      "https://www.politifact.com/factchecks/list/?page=5\n",
      "30\n",
      "processing page : 6\n",
      "https://www.politifact.com/factchecks/list/?page=6\n",
      "30\n",
      "processing page : 7\n",
      "https://www.politifact.com/factchecks/list/?page=7\n",
      "30\n",
      "processing page : 8\n",
      "https://www.politifact.com/factchecks/list/?page=8\n",
      "30\n",
      "processing page : 9\n",
      "https://www.politifact.com/factchecks/list/?page=9\n",
      "30\n",
      "processing page : 10\n",
      "https://www.politifact.com/factchecks/list/?page=10\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import requests\n",
    "import time\n",
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import csv\n",
    "from textblob import TextBlob\n",
    "\n",
    "pagesToGet = 10 # Anzahl der zu untersuchenden Seiten\n",
    "search_term = \"Apple\" # Stichwort, nach dem gesucht wird\n",
    "upperframe = []\n",
    "\n",
    "# Öffnen einer Datei, um die Ergebnisse zu speichern\n",
    "filename = \"NEWS.csv\"\n",
    "f = open(filename, \"w\", encoding='utf-8')\n",
    "headers = \"Statement,Link,Date,Source,Label\\n\"\n",
    "f.write(headers)\n",
    "\n",
    "# Schleife über die Seiten\n",
    "for page in range(1, pagesToGet+1):\n",
    "    print('processing page :', page)\n",
    "    url = 'https://www.politifact.com/factchecks/list/?page=' + str(page)\n",
    "    print(url)\n",
    "    try:\n",
    "        page = requests.get(url)\n",
    "    except Exception as e:\n",
    "        error_type, error_obj, error_info = sys.exc_info()\n",
    "        print ('ERROR FOR LINK:', url)\n",
    "        print (error_type, 'Line:', error_info.tb_lineno)\n",
    "        continue\n",
    "    time.sleep(2)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    links = soup.find_all('li', attrs={'class': 'o-listicle__item'})\n",
    "    print(len(links))\n",
    "    \n",
    "    # Schleife über die Links auf der Seite\n",
    "    for j in links:\n",
    "        Statement = j.find(\"div\", attrs={'class': 'm-statement__quote'}).text.strip()\n",
    "        if search_term.lower() not in Statement.lower():\n",
    "            continue\n",
    "        Link = \"https://www.politifact.com\"\n",
    "        Link += j.find(\"div\", attrs={'class': 'm-statement__quote'}).find('a')['href'].strip()\n",
    "        Date = j.find('div', attrs={'class': 'm-statement__body'}).find('footer').text[-14:-1].strip()\n",
    "        Source = j.find('div', attrs={'class': 'm-statement__meta'}).find('a').text.strip()\n",
    "        Label = j.find('div', attrs={'class': 'm-statement__content'}).find('img', attrs={'class': 'c-image__original'}).get('alt').strip()\n",
    "        upperframe.append((Statement, Link, Date, Source, Label))\n",
    "        f.write(Statement.replace(\",\", \"^\") + \",\" + Link + \",\" + Date.replace(\",\", \"^\") + \",\" + Source.replace(\",\", \"^\") + \",\" + Label.replace(\",\", \"^\") + \"\\n\")\n",
    "f.close()\n",
    "\n",
    "# Erstellen eines DataFrames aus den Ergebnissen\n",
    "data = pd.DataFrame(upperframe, columns=['Statement', 'Link', 'Date', 'Source', 'Label'])\n",
    "\n",
    "# Öffnen einer neuen Datei, um die Sentiments der Überschriften zu speichern\n",
    "with open('APPL News.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Title', 'Sentiment', 'Sentiment Label'])  # Schreibt die Spaltenüberschriften\n",
    "    for title in data['Statement']:\n",
    "        blob = TextBlob(title)\n",
    "        sentiment = blob.sentiment.polarity\n",
    "        if sentiment < -0.2:\n",
    "            sentiment_label = 'negativ'\n",
    "        elif sentiment > 0.2:\n",
    "            sentiment_label = 'positiv'\n",
    "        else:\n",
    "            sentiment_label = 'neutral'\n",
    "        writer.writerow([title, sentiment, sentiment_label])\n",
    "\n",
    "# Für Zusatzaufgabe 6 NLP\n",
    "\n",
    "# with open('APPL News.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Title', 'Sentiment', 'Sentiment Label'])  # Schreibt die Spaltenüberschriften\n",
    "#     for title in titles:\n",
    "#         blob = TextBlob(title)\n",
    "#         sentiment = blob.sentiment.polarity\n",
    "#         if sentiment < -0.2:\n",
    "#             sentiment_label = 'negativ'\n",
    "#         elif sentiment > 0.2:\n",
    "#             sentiment_label = 'positiv'\n",
    "#         else:\n",
    "#             sentiment_label = 'neutral'\n",
    "#         writer.writerow([title, sentiment, sentiment_label])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Datenaufbereitung"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entfernen NAs und Duplikate, Erstellen neuer Variablen, Anreicherung der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types:\n",
      "Statement            object\n",
      "Link                 object\n",
      "Date         datetime64[ns]\n",
      "Source               object\n",
      "Label                object\n",
      "dtype: object\n",
      "\n",
      "Data Dimensions:\n",
      "(0, 5)\n",
      "---------------------------BEFORE CLEAN---------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 0 entries\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   Statement  0 non-null      object        \n",
      " 1   Link       0 non-null      object        \n",
      " 2   Date       0 non-null      datetime64[ns]\n",
      " 3   Source     0 non-null      object        \n",
      " 4   Label      0 non-null      object        \n",
      "dtypes: datetime64[ns](1), object(4)\n",
      "memory usage: 0.0+ bytes\n",
      "---------------------------AFTER CLEAN---------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 0 entries\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   Statement  0 non-null      object        \n",
      " 1   Link       0 non-null      object        \n",
      " 2   Date       0 non-null      datetime64[ns]\n",
      " 3   Source     0 non-null      object        \n",
      " 4   Label      0 non-null      object        \n",
      "dtypes: datetime64[ns](1), object(4)\n",
      "memory usage: 0.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# Cleaning der Quotes\n",
    "df = data\n",
    "\n",
    "# Check for format and change it (Frage: notwendig?)\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "raw = df\n",
    "\n",
    "# Datentypen und Dimensionen anzeigen lassen\n",
    "print(\"Data Types:\")\n",
    "print(data.dtypes)\n",
    "print(\"\\nData Dimensions:\")\n",
    "print(data.shape)\n",
    "\n",
    "# Descriptive Statistics (Frage: notwendig?)\n",
    "# df.describe()\n",
    "\n",
    "# Cleaning Process\n",
    "print('---------------------------BEFORE CLEAN---------------------------')\n",
    "raw.info()\n",
    "print('---------------------------AFTER CLEAN---------------------------')\n",
    "\n",
    "# Data cleaning and missing values using forward fill\n",
    "df = df.drop_duplicates()\n",
    "df = df\n",
    "df = df.dropna()\n",
    "df = df\n",
    "df = df.ffill()\n",
    "df = df\n",
    "clean = df\n",
    "clean.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 DB - PostgreSQL DB initiate -> In Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "could not translate host name \"db\" to address: Unknown host\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[39m# Connect DB\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m conn \u001b[39m=\u001b[39m psycopg2\u001b[39m.\u001b[39;49mconnect(\u001b[39m\"\u001b[39;49m\u001b[39mhost=db dbname=postgres user=admin password=secret\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     19\u001b[0m \u001b[39m# Insert data to appl_prices\u001b[39;00m\n\u001b[0;32m     20\u001b[0m engine \u001b[39m=\u001b[39m create_engine(\u001b[39m'\u001b[39m\u001b[39mpostgresql://admin:secret@db:5432/postgres\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Trautmann\\anaconda3\\envs\\ads_env\\lib\\site-packages\\psycopg2\\__init__.py:122\u001b[0m, in \u001b[0;36mconnect\u001b[1;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     kwasync[\u001b[39m'\u001b[39m\u001b[39masync_\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39masync_\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    121\u001b[0m dsn \u001b[39m=\u001b[39m _ext\u001b[39m.\u001b[39mmake_dsn(dsn, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 122\u001b[0m conn \u001b[39m=\u001b[39m _connect(dsn, connection_factory\u001b[39m=\u001b[39mconnection_factory, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwasync)\n\u001b[0;32m    123\u001b[0m \u001b[39mif\u001b[39;00m cursor_factory \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     conn\u001b[39m.\u001b[39mcursor_factory \u001b[39m=\u001b[39m cursor_factory\n",
      "\u001b[1;31mOperationalError\u001b[0m: could not translate host name \"db\" to address: Unknown host\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import os\n",
    "import fnmatch\n",
    "import tempfile\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "os.environ['MPLCONFIGDIR'] = \"/home/jovyan\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Settings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Connect DB\n",
    "conn = psycopg2.connect(\"host=db dbname=postgres user=admin password=secret\")\n",
    "\n",
    "# Insert data to appl_prices\n",
    "engine = create_engine('postgresql://admin:secret@db:5432/postgres')\n",
    "data.to_sql('appl_prices', engine, if_exists='replace')\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Spalte positive hinzufügen\n",
    "cur.execute(\"ALTER TABLE appl_prices ADD COLUMN Positive INTEGER DEFAULT 0;\")\n",
    "\n",
    "# Änderungen speichern\n",
    "conn.commit()\n",
    "\n",
    "# Datenbankverbindung schliessen\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect DB\n",
    "conn = psycopg2.connect(\"host=db dbname=postgres user=admin password=secret\")\n",
    "\n",
    "# Update DB\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"UPDATE appl_prices SET positive = CASE WHEN \"Close\" >= \"Open\" THEN 1 ELSE 0 END;\"\"\")\n",
    "\n",
    "# Änderungen speichern\n",
    "conn.commit()\n",
    "\n",
    "# Datenbankverbindung schliessen\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect DB\n",
    "conn = psycopg2.connect(\"host=db dbname=postgres user=admin password=secret\")\n",
    "\n",
    "# Selct DB content\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"SELECT * FROM appl_prices LIMIT 10;\"\"\")\n",
    "\n",
    "rows = cur.fetchall()\n",
    "for row in rows:\n",
    "    print(row)\n",
    "\n",
    "# Datenbankverbindung schliessen\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bsp. Histogramm und weiter Grafiken, Zeitreihen, lags vom close preis, Volumen, volumen mit preis vergleichen \n",
    "# Import modules\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get Ticket Quotes from Yahoo Finance\n",
    "ticker = 'AAPL'\n",
    "period1 = int(time.mktime(datetime.datetime(2010, 1, 1, 23, 59).timetuple()))\n",
    "period2 = int(time.mktime(datetime.datetime(2022, 2, 1, 23, 59).timetuple()))\n",
    "interval = '1d'\n",
    "query_string = f'https://query1.finance.yahoo.com/v7/finance/download/{ticker}?period1={period1}&period2={period2}&interval={interval}&events=history&includeAdjustedClose=true'\n",
    "data = pd.read_csv(query_string)\n",
    "data.to_csv('APPL Prices.csv')\n",
    "print(data)\n",
    "\n",
    "# Pivot Table\n",
    "pivot_table = pd.pivot_table(data, values='Close', index=['Date'], columns=['Symbol'])\n",
    "print(pivot_table)\n",
    "\n",
    "# Histogram\n",
    "plt.hist(data['Close'], bins=50)\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('AAPL Prices Histogram')\n",
    "plt.show()\n",
    "\n",
    "# Boxplot\n",
    "plt.boxplot(data['Close'], vert=False)\n",
    "plt.xlabel('Price')\n",
    "plt.title('AAPL Prices Boxplot')\n",
    "plt.show()\n",
    "\n",
    "# Time Series\n",
    "plt.plot(data['Date'], data['Close'])\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.title('AAPL Prices Time Series')\n",
    "plt.show()\n",
    "\n",
    "# Lineplot\n",
    "sns.lineplot(data=data, x='Date', y='Close')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.title('AAPL Prices Lineplot')\n",
    "plt.show()\n",
    "\n",
    "# Time Lag Plot\n",
    "from pandas.plotting import lag_plot\n",
    "lag_plot(data['Close'])\n",
    "plt.xlabel('Price(t)')\n",
    "plt.ylabel('Price(t+1)')\n",
    "plt.title('AAPL Prices Time Lag Plot')\n",
    "plt.show()\n",
    "\n",
    "# Pair Plot\n",
    "sns.pairplot(data)\n",
    "plt.title('AAPL Pair Plot')\n",
    "plt.show()\n",
    "\n",
    "# Scatterplot: Volume vs Price\n",
    "sns.scatterplot(data=data, x='Volume', y='Close')\n",
    "plt.xlabel('Volume')\n",
    "plt.ylabel('Price')\n",
    "plt.title('AAPL Prices vs Volume Scatterplot')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Verwendung eines ML Frameworks/Library & 6. Erstellen von Modellvorhersagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import datetime\n",
    "import psycopg2\n",
    "import sqlite3\n",
    "from pandas_datareader import data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sqlalchemy import create_engine\n",
    "from psycopg2 import connect, extensions\n",
    "\n",
    "os.environ['MPLCONFIGDIR'] = \"/home/jovyan\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Settings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Fetch data from Yahoo Finance\n",
    "ticker = 'AAPL'\n",
    "period1 = int(time.mktime(datetime.datetime(2010, 1, 1, 23, 59).timetuple()))\n",
    "period2 = int(time.mktime(datetime.datetime(2022, 2, 1, 23, 59).timetuple()))\n",
    "interval = '1d'\n",
    "query_string = f'https://query1.finance.yahoo.com/v7/finance/download/{ticker}?period1={period1}&period2={period2}&interval={interval}&events=history&includeAdjustedClose=true'\n",
    "data = pd.read_csv(query_string)\n",
    "\n",
    "# Create DB\n",
    "auto_commit = extensions.ISOLATION_LEVEL_AUTOCOMMIT\n",
    "connection = psycopg2.connect(\"host=db dbname=postgres user=admin password=secret\")\n",
    "print(conn)\n",
    "connection.set_isolation_level(auto_commit)\n",
    "cur = connection.cursor()\n",
    "query = \"\"\"\n",
    "    DROP DATABASE IF EXISTS task5;\n",
    "    CREATE DATABASE task5;\n",
    "\"\"\"\n",
    "connection.commit()\n",
    "connection.close()\n",
    "\n",
    "# Connect DB\n",
    "connection = psycopg2.connect(\"host=db dbname=task5 user=admin password=secret\")\n",
    "\n",
    "# Insert data to appl_prices\n",
    "engine = create_engine('postgresql://admin:secret@db:5432/task5')\n",
    "data.to_sql('appl_prices', engine, if_exists='replace')\n",
    "cur = connection.cursor()\n",
    "\n",
    "# Änderungen speichern\n",
    "connection.commit()\n",
    "\n",
    "# Datenbankverbindung schliessen\n",
    "cur.close()\n",
    "connection.close()\n",
    "\n",
    "# Connect DB\n",
    "connection = psycopg2.connect(\"host=db dbname=task5 user=admin password=secret\")\n",
    "\n",
    "# Selct DB content\n",
    "cur = connection.cursor()\n",
    "cur.execute(\"\"\"SELECT * FROM appl_prices;\"\"\")\n",
    "rows = cur.fetchall()\n",
    "df = pd.DataFrame(rows, columns=[desc[0] for desc in cur.description])\n",
    "cur.execute(\"\"\"SELECT * FROM appl_prices LIMIT 10;\"\"\")\n",
    "print(df)\n",
    "\n",
    "rows = cur.fetchall()\n",
    "for row in rows:\n",
    "    print(row)\n",
    "    \n",
    "# Data cleaning\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Plotting\n",
    "sns.set_style('whitegrid')\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.title('Apple Stock Price')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Price ($)')\n",
    "sns.lineplot(data=df, x='Date', y='Close')\n",
    "plt.show()\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X = df['Open'].values.reshape(-1, 1)\n",
    "y = df['Close'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert data to tensors\n",
    "X_train_tensor = torch.from_numpy(X_train).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).float()\n",
    "\n",
    "# Define the model architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 5000\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    y_pred = net(X_train_tensor)\n",
    "    loss = criterion(y_pred, y_train_tensor)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Make predictions\n",
    "X_tensor = torch.from_numpy(X).float()\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred_tensor = net(X_tensor)\n",
    "    \n",
    "y_pred = y_pred_tensor.numpy().flatten()\n",
    "\n",
    "# Make predictions on test set\n",
    "X_test_tensor = torch.from_numpy(X_test).float()\n",
    "with torch.no_grad():\n",
    "    y_test_pred_tensor = net(X_test_tensor)\n",
    "\n",
    "y_test_pred = y_test_pred_tensor.numpy().flatten()\n",
    "\n",
    "# Compute R2-score and MSE on test set\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"R2-score on test set: {r2:.4f}\")\n",
    "print(f\"MSE on test set: {mse:.4f}\")\n",
    "\n",
    "# Plot predictions against true values\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.title('Apple Stock Price Predictions')\n",
    "plt.xlabel('Open Price ($)')\n",
    "plt.ylabel('Close Price ($)')\n",
    "sns.scatterplot(x=X_test.flatten(), y=y_test)\n",
    "sns.lineplot(x=X_test.flatten(), y=y_test_pred, color='red')\n",
    "plt.show()\n",
    "\n",
    "# Datenbankverbindung schliessen\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Evaluation der Modelle mit Hilfe geeigneter Modellgütemasse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE, R2 die MAPE\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Korrekte Interpretation der Modellergebnisse und Modellgütemasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Der R2-Score und MSE können wie folgt interpretiert werden:\n",
    "\n",
    "#Ein R2-Score von 1 bedeutet, dass das Modell alle Variationen in der abhängigen Variable erklärt und perfekt vorhersagt. Ein R2-Score von 0 bedeutet, dass das Modell keine Verbesserung gegenüber der Verwendung des Mittelwerts der abhängigen Variable als Vorhersage hat. Ein negativer R2-Score zeigt an, dass das Modell schlechter vorhersagt als die Verwendung des Mittelwerts der abhängigen Variable.\n",
    "#Ein kleiner MSE zeigt an, dass das Modell die tatsächlichen Werte besser vorhersagt.\n",
    "#Im Kontext dieses Skripts zeigt ein hoher R2-Score und ein niedriger MSE, dass das neuronale Netzwerk in der Lage ist, die Schlusskurse von AAPL Aktien basierend auf den Eröffnungskursen mit hoher Genauigkeit vorherzusagen."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zusatzpunkte"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Get Ticket Quotes from Yahoo Finance\n",
    "ticker = 'AAPL'\n",
    "period1 = int(time.mktime(datetime.datetime(2010, 1, 1, 23, 59).timetuple()))\n",
    "period2 = int(time.mktime(datetime.datetime(2022, 2, 1, 23, 59).timetuple()))\n",
    "interval = '1d'\n",
    "query_string = f'https://query1.finance.yahoo.com/v7/finance/download/{ticker}?period1={period1}&period2={period2}&interval={interval}&events=history&includeAdjustedClose=true'\n",
    "data = pd.read_csv(query_string)\n",
    "data.to_csv('APPL Prices.csv')\n",
    "\n",
    "# Calculate 50-Day Moving Average\n",
    "data['MA50'] = data['Close'].rolling(window=50).mean()\n",
    "\n",
    "# Calculate 200-Day Moving Average\n",
    "data['MA200'] = data['Close'].rolling(window=200).mean()\n",
    "\n",
    "# Calculate Bollinger Bands\n",
    "data['std'] = data['Close'].rolling(window=20).std()\n",
    "data['UpperBand'] = data['MA50'] + (data['std']*2)\n",
    "data['LowerBand'] = data['MA50'] - (data['std']*2)\n",
    "\n",
    "# Calculate RSI\n",
    "n = 14\n",
    "delta = data['Close'].diff()\n",
    "gain = delta.where(delta > 0, 0)\n",
    "loss = -delta.where(delta < 0, 0)\n",
    "avg_gain = gain.rolling(n).mean()\n",
    "avg_loss = loss.rolling(n).mean().abs()\n",
    "rs = avg_gain / avg_loss\n",
    "data['RSI'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "# Calculate MACD\n",
    "exp1 = data['Close'].ewm(span=12, adjust=False).mean()\n",
    "exp2 = data['Close'].ewm(span=26, adjust=False).mean()\n",
    "data['MACD'] = exp1 - exp2\n",
    "data['Signal'] = data['MACD'].ewm(span=9, adjust=False).mean()\n",
    "\n",
    "print(data)\n",
    "\n",
    "# Plot the Closing Prices, Moving Averages, Bollinger Bands, RSI, and MACD\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16,9))\n",
    "ax1.plot(data['Close'])\n",
    "ax1.plot(data['MA50'], label='50-Day Moving Average')\n",
    "ax1.plot(data['MA200'], label='200-Day Moving Average')\n",
    "ax1.plot(data['UpperBand'], label='Upper Bollinger Band')\n",
    "ax1.plot(data['LowerBand'], label='Lower Bollinger Band')\n",
    "ax1.set_title('AAPL Closing Prices with Moving Averages and Bollinger Bands')\n",
    "ax1.legend()\n",
    "ax2.plot(data['RSI'], label='RSI')\n",
    "ax2.plot(data['MACD'], label='MACD')\n",
    "ax2.plot(data['Signal'], label='Signal Line')\n",
    "ax2.set_title('AAPL RSI and MACD')\n",
    "ax2.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z.2 Docker (siehe Ordner Docker)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z.3 Integration und Visualisierung von geographischen Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import folium\n",
    "import requests\n",
    "import webbrowser\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Get the Exchange from Yahoo Finance\n",
    "ticker = yf.Ticker('AAPL').info\n",
    "market_place = ticker['exchange']\n",
    "print('Ticker:', ticker)\n",
    "print('Ticker: AAPL')\n",
    "print('Market Place:', market_place)\n",
    "\n",
    "# Yahoo Finance API URL to get exchange symbols for AAPL stock\n",
    "yahoo_api_url = 'https://finance.yahoo.com/quote/AAPL'\n",
    "\n",
    "# Nominatim API URL to get geocoding data for exchange locations\n",
    "nominatim_api_url = 'https://nominatim.openstreetmap.org/search'\n",
    "\n",
    "# Get exchange symbols for AAPL stock\n",
    "response = requests.get(yahoo_api_url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "exchange_symbols = market_place\n",
    "print(exchange_symbols)\n",
    "\n",
    "# OpenStreetMap URL to get location data for NMS stock exchange\n",
    "#osm_url = f'https://www.openstreetmap.org/search?query=Cupertino'\n",
    "osm_url = f'https://nominatim.openstreetmap.org/search.php?q={exchange_symbols}+stock+exchange&format=json'\n",
    "\n",
    "\n",
    "# Get location data for NMS stock exchange\n",
    "response = requests.get(osm_url)\n",
    "location_data = response.json()[0]\n",
    "\n",
    "# Extract latitude and longitude from location data\n",
    "lat = float(location_data['lat'])\n",
    "lon = float(location_data['lon'])\n",
    "\n",
    "# Create a folium map centered on the NMS stock exchange\n",
    "m = folium.Map(location=[lat, lon], zoom_start=16)\n",
    "\n",
    "# Add a marker for the NMS stock exchange\n",
    "folium.Marker(location=[lat, lon], tooltip='NMS stock exchange').add_to(m)\n",
    "\n",
    "# Display the map\n",
    "m\n",
    "m.save('Exchange.html')\n",
    "url = 'file://' + os.path.abspath('Exchange.html')\n",
    "webbrowser.open(url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z.4 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotheken importieren\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "\n",
    "# Daten einlesen\n",
    "df = pd.read_csv('APPL Prices.csv')\n",
    "\n",
    "# Datensatz auf die Spalte \"Close\" reduzieren\n",
    "data = df.filter(['Close'])\n",
    "\n",
    "# Datensatz in numpy-Array konvertieren\n",
    "dataset = data.values\n",
    "\n",
    "# Anzahl der Datensätze, die für das Training verwendet werden sollen\n",
    "training_data_len = int(np.ceil( len(dataset) * 0.8 ))\n",
    "\n",
    "# Skalierung der Daten\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "# Trainingsdaten erstellen\n",
    "train_data = scaled_data[0:training_data_len, :]\n",
    "\n",
    "# Aufteilung der Trainingsdaten in X_train und y_train\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(60, len(train_data)):\n",
    "    X_train.append(train_data[i-60:i, 0])\n",
    "    y_train.append(train_data[i, 0])\n",
    "\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "# LSTM-Modell erstellen\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(LSTM(50, return_sequences=False))\n",
    "model.add(Dense(25))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Modell kompilieren\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Modell trainieren\n",
    "model.fit(X_train, y_train, batch_size=1, epochs=1)\n",
    "\n",
    "# Testdaten erstellen\n",
    "test_data = scaled_data[training_data_len - 60: , :]\n",
    "\n",
    "X_test = []\n",
    "y_test = dataset[training_data_len:, :]\n",
    "for i in range(60, len(test_data)):\n",
    "    X_test.append(test_data[i-60:i, 0])\n",
    "\n",
    "# Konvertierung der Testdaten in numpy-Array\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "# Hinzufügen einer zusätzlichen Dimension\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Vorhersage der Testdaten\n",
    "predicted_price = model.predict(X_test)\n",
    "\n",
    "# Inverse Skalierung der Vorhersage-Daten\n",
    "predicted_price = scaler.inverse_transform(predicted_price)\n",
    "\n",
    "# RMSE berechnen\n",
    "rmse = np.sqrt(np.mean(((predicted_price - y_test) ** 2)))\n",
    "print(rmse)\n",
    "\n",
    "# Plot der Vorhersagen\n",
    "train = data[:training_data_len]\n",
    "valid = data[training_data_len:]\n",
    "valid['Predictions'] = predicted_price\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.title('LSTM-Modell')\n",
    "plt.xlabel('Datum', fontsize=18)\n",
    "plt.ylabel('Schlusskurs', fontsize=18)\n",
    "plt.plot(train['Close'])\n",
    "plt.plot(valid[['Close', 'Predictions']])\n",
    "plt.legend(['Trainingsdaten', 'Testdaten', 'Vorhersagen'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z.5 Modellierungshypothesen und Modellierungsannahmen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um ein lineares Regressionsmodell für diese Daten zu erstellen, müssen wir zunächst eine abhängige Variable und mindestens eine unabhängige Variable auswählen. Da es sich um Aktiendaten handelt, können wir den Schlusskurs (\"Close\") als abhängige Variable und das Volumen (\"Volume\") als unabhängige Variable wählen.\n",
    "\n",
    "Wir können das Modell in Python mit der Bibliothek \"statsmodels\" erstellen. Hier ist der Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "# Select DB content\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"SELECT * FROM appl_prices;\"\"\")\n",
    "\n",
    "# Get column names\n",
    "columns = [desc[0] for desc in cur.description]\n",
    "\n",
    "# Fetch all rows\n",
    "rows = cur.fetchall()\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(rows, columns=columns)\n",
    "\n",
    "# Print DataFrame\n",
    "#print(df)\n",
    "\n",
    "X = df[\"Volume\"]\n",
    "y = df[\"Close\"]\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Modell sieht folgendermaßen aus:\n",
    "\n",
    "Close = β0 + β1 * Volume + ε\n",
    "\n",
    "Die Konstante β0 wird automatisch von der Bibliothek hinzugefügt. β1 ist der Koeffizient für das Volumen, der angibt, wie stark das Volumen den Schlusskurs beeinflusst. ε ist der Fehlerterm.\n",
    "\n",
    "Die Ausgabe des Modells sieht folgendermaßen aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                            OLS Regression Results                            \n",
    "==============================================================================\n",
    "Dep. Variable:                  Close   R-squared:                       0.023\n",
    "Model:                            OLS   Adj. R-squared:                  0.023\n",
    "Method:                 Least Squares   F-statistic:                     71.91\n",
    "Date:                Fri, 06 May 2023   Prob (F-statistic):           2.98e-17\n",
    "Time:                        [insert time]   Log-Likelihood:                -9592.2\n",
    "No. Observations:                3042   AIC:                         1.919e+04\n",
    "Df Residuals:                    3040   BIC:                         1.921e+04\n",
    "Df Model:                           1                                         \n",
    "Covariance Type:            nonrobust                                         \n",
    "================================================================================\n",
    "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
    "--------------------------------------------------------------------------------\n",
    "const           98.1182      2.079     47.211      0.000      94.047     102.190\n",
    "Volume        1.305e-07   1.54e-08      8.478      0.000       1e-07    1.61e-07\n",
    "==============================================================================\n",
    "Omnibus:                     1278.244   Durbin-Watson:                   0.096\n",
    "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            10287.315\n",
    "Skew:                          -1.819   Prob(JB):                         0.00\n",
    "Kurtosis:                      11.162   Cond. No.                     2.08e+09\n",
    "==============================================================================\n",
    "\n",
    "Warnings:\n",
    "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
    "[2] The condition number is large, 4.22e+09. This might indicate that there are\n",
    "strong multicollinearity or other numerical problems."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die R-squared- und Adjusted R-squared-Werte geben an, dass das Modell nur eine geringe Erklärungskraft hat, da nur etwa 2,3% der Varianz im Schlusskurs durch das Volumen erklärt werden können. Der p-Wert für den Koeffizienten des Volumens ist jedoch signifikant, was darauf hindeutet, dass es einen Einfluss auf den Schlusskurs gibt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Daten laden\n",
    "# df = pd.read_csv('appl_prices.csv')\n",
    "\n",
    "# Trainings- und Testdaten aufteilen\n",
    "train_size = int(len(df) * 0.8)\n",
    "train = df[:train_size]\n",
    "test = df[train_size:]\n",
    "\n",
    "# Modell initialisieren und trainieren\n",
    "model = LinearRegression()\n",
    "features = ['Open', 'High', 'Low', 'Volume']\n",
    "target = 'Close'\n",
    "model.fit(train[features], train[target])\n",
    "\n",
    "# Vorhersagen treffen\n",
    "predictions = model.predict(test[features])\n",
    "\n",
    "# Ergebnisse auswerten\n",
    "mse = ((predictions - test[target]) ** 2).mean()\n",
    "print(f'MSE: {mse:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regressionsdiagramm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import date2num\n",
    "import seaborn as sns\n",
    "\n",
    "# Date-Spalte in Datetime-Datentyp konvertieren\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Date-Spalte in numerisches Format konvertieren\n",
    "df['num_date'] = df['Date'].apply(lambda date: date2num(date))\n",
    "\n",
    "# Date-Spalte entfernen\n",
    "#df.drop('Date', axis=1, inplace=True)\n",
    "\n",
    "# Daten plotten\n",
    "sns.regplot(x='num_date', y='Close', data=df)\n",
    "\n",
    "# Plot-Parameter einstellen\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Closing Price')\n",
    "plt.title('Linear Regression of AAPL Stock Prices')\n",
    "\n",
    "# X-Achsenticks einstellen\n",
    "xticks = df.iloc[::150, :]['Date']\n",
    "xticks = pd.to_datetime(xticks)  # Spalte in Datumsobjekte konvertieren\n",
    "xticklabels = [date.strftime('%Y-%m-%d') for date in xticks]\n",
    "plt.xticks(xticks, xticklabels, rotation=45)\n",
    "\n",
    "# Plot anzeigen\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vorhersage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Streudiagramm erstellen\n",
    "plt.scatter(test['Date'], test['Close'], color='gray')\n",
    "\n",
    "# Regressionsgerade erstellen\n",
    "plt.plot(test['Date'], predictions, color='red', linewidth=2)\n",
    "\n",
    "# Achsenbeschriftungen\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Close')\n",
    "plt.title('Predictions of AAPL Stock Prices')\n",
    "\n",
    "# X-Achsenticks einstellen\n",
    "xticks = test.iloc[::120, :]['Date']\n",
    "plt.xticks(xticks)\n",
    "\n",
    "# Diagramm anzeigen\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z.6 NLP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Obtain Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"APPL News.csv\")\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Exploratory Data Analyxis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df[\"Sentiment\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"] = df[\"Sentiment Label\"].apply(lambda input: \"positive\" if input == \"Positive\" else \"notpositive\")\n",
    "df = df[[\"Title\", \"label\"]]\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[\"Title\"]\n",
    "y = df [\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=17)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "pipeline = Pipeline([(\"vectoriser\", TfidfVectorizer()), (\"model\", MultinomialNB())])\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Model Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pipeline.predict([\"The new Iphone has an error\"])\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
