{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Datenerhebung mittels API & Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import time\n",
    "import datetime\n",
    "#sns.get_dataset_names()\n",
    "from pandas_datareader import data\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Yahoo Finance API: Aktienkurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date        Open        High         Low       Close   Adj Close  \\\n",
      "0     2010-01-04    7.622500    7.660714    7.585000    7.643214    6.505279   \n",
      "1     2010-01-05    7.664286    7.699643    7.616071    7.656429    6.516527   \n",
      "2     2010-01-06    7.656429    7.686786    7.526786    7.534643    6.412874   \n",
      "3     2010-01-07    7.562500    7.571429    7.466071    7.520714    6.401018   \n",
      "4     2010-01-08    7.510714    7.571429    7.466429    7.570714    6.443572   \n",
      "...          ...         ...         ...         ...         ...         ...   \n",
      "3037  2022-01-26  163.500000  164.389999  157.820007  159.690002  158.526489   \n",
      "3038  2022-01-27  162.449997  163.839996  158.279999  159.220001  158.059921   \n",
      "3039  2022-01-28  165.710007  170.350006  162.800003  170.330002  169.088974   \n",
      "3040  2022-01-31  170.160004  175.000000  169.509995  174.779999  173.506546   \n",
      "3041  2022-02-01  174.009995  174.839996  172.309998  174.610001  173.337784   \n",
      "\n",
      "         Volume  \n",
      "0     493729600  \n",
      "1     601904800  \n",
      "2     552160000  \n",
      "3     477131200  \n",
      "4     447610800  \n",
      "...         ...  \n",
      "3037  108275300  \n",
      "3038  121954600  \n",
      "3039  179935700  \n",
      "3040  115541600  \n",
      "3041   86213900  \n",
      "\n",
      "[3042 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "ticker = 'AAPL'\n",
    "period1 = int(time.mktime(datetime.datetime(2010, 1, 1, 23, 59).timetuple()))\n",
    "period2 = int(time.mktime(datetime.datetime(2022, 2, 1, 23, 59).timetuple()))\n",
    "interval = '1d'\n",
    "query_string = f'https://query1.finance.yahoo.com/v7/finance/download/{ticker}?period1={period1}&period2={period2}&interval={interval}&events=history&includeAdjustedClose=true'\n",
    "data = pd.read_csv(query_string)\n",
    "print(data)\n",
    "data.to_csv('APPL Prices.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing page : 1\n",
      "https://www.politifact.com/factchecks/list/?page=1\n",
      "30\n",
      "processing page : 2\n",
      "https://www.politifact.com/factchecks/list/?page=2\n",
      "30\n",
      "processing page : 3\n",
      "https://www.politifact.com/factchecks/list/?page=3\n",
      "30\n",
      "processing page : 4\n",
      "https://www.politifact.com/factchecks/list/?page=4\n",
      "30\n",
      "processing page : 5\n",
      "https://www.politifact.com/factchecks/list/?page=5\n",
      "30\n",
      "processing page : 6\n",
      "https://www.politifact.com/factchecks/list/?page=6\n",
      "30\n",
      "processing page : 7\n",
      "https://www.politifact.com/factchecks/list/?page=7\n",
      "30\n",
      "processing page : 8\n",
      "https://www.politifact.com/factchecks/list/?page=8\n",
      "30\n",
      "processing page : 9\n",
      "https://www.politifact.com/factchecks/list/?page=9\n",
      "30\n",
      "processing page : 10\n",
      "https://www.politifact.com/factchecks/list/?page=10\n",
      "30\n",
      "processing page : 11\n",
      "https://www.politifact.com/factchecks/list/?page=11\n",
      "30\n",
      "processing page : 12\n",
      "https://www.politifact.com/factchecks/list/?page=12\n",
      "30\n",
      "processing page : 13\n",
      "https://www.politifact.com/factchecks/list/?page=13\n",
      "30\n",
      "processing page : 14\n",
      "https://www.politifact.com/factchecks/list/?page=14\n",
      "30\n",
      "processing page : 15\n",
      "https://www.politifact.com/factchecks/list/?page=15\n",
      "30\n",
      "processing page : 16\n",
      "https://www.politifact.com/factchecks/list/?page=16\n",
      "30\n",
      "processing page : 17\n",
      "https://www.politifact.com/factchecks/list/?page=17\n",
      "30\n",
      "processing page : 18\n",
      "https://www.politifact.com/factchecks/list/?page=18\n",
      "30\n",
      "processing page : 19\n",
      "https://www.politifact.com/factchecks/list/?page=19\n",
      "30\n",
      "processing page : 20\n",
      "https://www.politifact.com/factchecks/list/?page=20\n",
      "30\n",
      "processing page : 21\n",
      "https://www.politifact.com/factchecks/list/?page=21\n",
      "30\n",
      "processing page : 22\n",
      "https://www.politifact.com/factchecks/list/?page=22\n",
      "30\n",
      "processing page : 23\n",
      "https://www.politifact.com/factchecks/list/?page=23\n",
      "30\n",
      "processing page : 24\n",
      "https://www.politifact.com/factchecks/list/?page=24\n",
      "30\n",
      "processing page : 25\n",
      "https://www.politifact.com/factchecks/list/?page=25\n",
      "30\n",
      "processing page : 26\n",
      "https://www.politifact.com/factchecks/list/?page=26\n",
      "30\n",
      "processing page : 27\n",
      "https://www.politifact.com/factchecks/list/?page=27\n",
      "30\n",
      "processing page : 28\n",
      "https://www.politifact.com/factchecks/list/?page=28\n",
      "30\n",
      "processing page : 29\n",
      "https://www.politifact.com/factchecks/list/?page=29\n",
      "30\n",
      "processing page : 30\n",
      "https://www.politifact.com/factchecks/list/?page=30\n",
      "30\n",
      "processing page : 31\n",
      "https://www.politifact.com/factchecks/list/?page=31\n",
      "30\n",
      "processing page : 32\n",
      "https://www.politifact.com/factchecks/list/?page=32\n",
      "30\n",
      "processing page : 33\n",
      "https://www.politifact.com/factchecks/list/?page=33\n",
      "30\n",
      "processing page : 34\n",
      "https://www.politifact.com/factchecks/list/?page=34\n",
      "0\n",
      "processing page : 35\n",
      "https://www.politifact.com/factchecks/list/?page=35\n",
      "30\n",
      "processing page : 36\n",
      "https://www.politifact.com/factchecks/list/?page=36\n"
     ]
    }
   ],
   "source": [
    "import urllib.request,sys,time\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "pagesToGet = 99\n",
    "search_term = \"Apple Inc.\" # Change this to the search term you want to use\n",
    "\n",
    "upperframe = []\n",
    "\n",
    "for page in range(1, pagesToGet+1):\n",
    "    print('processing page :', page)\n",
    "    url = 'https://www.politifact.com/factchecks/list/?page=' + str(page)\n",
    "    print(url)\n",
    "    try:\n",
    "        page = requests.get(url)\n",
    "    except Exception as e:\n",
    "        error_type, error_obj, error_info = sys.exc_info()\n",
    "        print ('ERROR FOR LINK:', url)\n",
    "        print (error_type, 'Line:', error_info.tb_lineno)\n",
    "        continue\n",
    "    time.sleep(2)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    frame = []\n",
    "    links = soup.find_all('li', attrs={'class': 'o-listicle__item'})\n",
    "    print(len(links))\n",
    "    filename = \"NEWS.csv\"\n",
    "    f = open(filename, \"w\", encoding='utf-8')\n",
    "    headers = \"Statement,Link,Date,Source,Label\\n\"\n",
    "    f.write(headers)\n",
    "    for j in links:\n",
    "        Statement = j.find(\"div\", attrs={'class': 'm-statement__quote'}).text.strip()\n",
    "        if search_term.lower() not in Statement.lower():\n",
    "            continue\n",
    "        Link = \"https://www.politifact.com\"\n",
    "        Link += j.find(\"div\", attrs={'class': 'm-statement__quote'}).find('a')['href'].strip()\n",
    "        Date = j.find('div', attrs={'class': 'm-statement__body'}).find('footer').text[-14:-1].strip()\n",
    "        Source = j.find('div', attrs={'class': 'm-statement__meta'}).find('a').text.strip()\n",
    "        Label = j.find('div', attrs={'class': 'm-statement__content'}).find('img', attrs={'class': 'c-image__original'}).get('alt').strip()\n",
    "        frame.append((Statement, Link, Date, Source, Label))\n",
    "        f.write(Statement.replace(\",\", \"^\") + \",\" + Link + \",\" + Date.replace(\",\", \"^\") + \",\" + Source.replace(\",\", \"^\") + \",\" + Label.replace(\",\", \"^\") + \"\\n\")\n",
    "    upperframe.extend(frame)\n",
    "f.close()\n",
    "data = pd.DataFrame(upperframe, columns=['Statement', 'Link', 'Date', 'Source', 'Label'])\n",
    "data.head()\n",
    "\n",
    "# Für Zusatzaufgabe 6 NLP\n",
    "\n",
    "with open('APPL News.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Title', 'Sentiment', 'Sentiment Label'])  # schreibt die Spaltenüberschriften\n",
    "    for title in titles:\n",
    "        blob = TextBlob(title)\n",
    "        sentiment = blob.sentiment.polarity\n",
    "        if sentiment < -0.2:\n",
    "            sentiment_label = 'negativ'\n",
    "        elif sentiment > 0.2:\n",
    "            sentiment_label = 'positiv'\n",
    "        else:\n",
    "            sentiment_label = 'neutral'\n",
    "        writer.writerow([title, sentiment, sentiment_label])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Datenaufbereitung"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entfernen NAs und Duplikate, Erstellen neuer Variablen, Anreicherung der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data\n",
    "\n",
    "# Descriptive Statistics\n",
    "df.describe()\n",
    "# Check for format and change it¶\n",
    "df.info()\n",
    "\n",
    "# Data cleaning --> Hier noch mehr Befehle suchen\n",
    "df = data.drop_duplicates()\n",
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 DB - PostgreSQL DB initiate -> In Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os\n",
    "import fnmatch\n",
    "import tempfile\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "os.environ['MPLCONFIGDIR'] = \"/home/jovyan\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Settings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Connect DB\n",
    "conn = psycopg2.connect(\"host=db dbname=postgres user=admin password=secret\")\n",
    "\n",
    "# Insert data to appl_prices\n",
    "engine = create_engine('postgresql://admin:secret@db:5432/postgres')\n",
    "data.to_sql('appl_prices', engine, if_exists='replace')\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Spalte positive hinzufügen\n",
    "cur.execute(\"ALTER TABLE appl_prices ADD COLUMN Positive INTEGER DEFAULT 0;\")\n",
    "\n",
    "# Änderungen speichern\n",
    "conn.commit()\n",
    "\n",
    "# Datenbankverbindung schliessen\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect DB\n",
    "conn = psycopg2.connect(\"host=db dbname=postgres user=admin password=secret\")\n",
    "\n",
    "# Update DB\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"UPDATE appl_prices SET positive = CASE WHEN \"Close\" >= \"Open\" THEN 1 ELSE 0 END;\"\"\")\n",
    "\n",
    "# Änderungen speichern\n",
    "conn.commit()\n",
    "\n",
    "# Datenbankverbindung schliessen\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect DB\n",
    "conn = psycopg2.connect(\"host=db dbname=postgres user=admin password=secret\")\n",
    "\n",
    "# Selct DB content\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"SELECT * FROM appl_prices LIMIT 10;\"\"\")\n",
    "\n",
    "rows = cur.fetchall()\n",
    "for row in rows:\n",
    "    print(row)\n",
    "\n",
    "# Datenbankverbindung schliessen\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Daten aus DB lesen und bearbeiten\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas_datareader import data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Exploratory data analysis\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "\n",
    "# Plotting\n",
    "sns.set_style('whitegrid')\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.title('Apple Stock Price')\n",
    "plt.xlabel('Year')\n",
    "\n",
    "plt.ylabel('Price ($)')\n",
    "sns.lineplot(data=df, x='Date', y='Close')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.title('Daily Change in Apple Stock Price')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Change in price ($)')\n",
    "sns.lineplot(data=df, x='Date', y='Close').set(ylabel='Price ($)', xlabel='Year')\n",
    "sns.lineplot(data=df, x='Date', y=df['Close'].diff()).set(ylabel='Change in price ($)', xlabel='Year')\n",
    "plt.legend(labels=['Price', 'Daily Change'])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.title('Apple Stock Price Distribution')\n",
    "sns.histplot(data=df, x='Close', bins=30)\n",
    "plt.show()\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X = df['Open'].values.reshape(-1, 1)\n",
    "y = df['Close'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'R-squared: {r2:.2f}')\n",
    "print"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Verwendung eines ML Frameworks/Library & 6. Erstellen von Modellvorhersagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import datetime\n",
    "import psycopg2\n",
    "import sqlite3\n",
    "from pandas_datareader import data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sqlalchemy import create_engine\n",
    "from psycopg2 import connect, extensions\n",
    "\n",
    "os.environ['MPLCONFIGDIR'] = \"/home/jovyan\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Settings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Fetch data from Yahoo Finance\n",
    "ticker = 'AAPL'\n",
    "period1 = int(time.mktime(datetime.datetime(2010, 1, 1, 23, 59).timetuple()))\n",
    "period2 = int(time.mktime(datetime.datetime(2022, 2, 1, 23, 59).timetuple()))\n",
    "interval = '1d'\n",
    "query_string = f'https://query1.finance.yahoo.com/v7/finance/download/{ticker}?period1={period1}&period2={period2}&interval={interval}&events=history&includeAdjustedClose=true'\n",
    "data = pd.read_csv(query_string)\n",
    "\n",
    "# Create DB\n",
    "auto_commit = extensions.ISOLATION_LEVEL_AUTOCOMMIT\n",
    "connection = psycopg2.connect(\"host=db dbname=postgres user=admin password=secret\")\n",
    "print(conn)\n",
    "connection.set_isolation_level(auto_commit)\n",
    "cur = connection.cursor()\n",
    "query = \"\"\"\n",
    "    DROP DATABASE IF EXISTS task5;\n",
    "    CREATE DATABASE task5;\n",
    "\"\"\"\n",
    "connection.commit()\n",
    "connection.close()\n",
    "\n",
    "# Connect DB\n",
    "connection = psycopg2.connect(\"host=db dbname=task5 user=admin password=secret\")\n",
    "\n",
    "# Insert data to appl_prices\n",
    "engine = create_engine('postgresql://admin:secret@db:5432/task5')\n",
    "data.to_sql('appl_prices', engine, if_exists='replace')\n",
    "cur = connection.cursor()\n",
    "\n",
    "# Änderungen speichern\n",
    "connection.commit()\n",
    "\n",
    "# Datenbankverbindung schliessen\n",
    "cur.close()\n",
    "connection.close()\n",
    "\n",
    "# Connect DB\n",
    "connection = psycopg2.connect(\"host=db dbname=task5 user=admin password=secret\")\n",
    "\n",
    "# Selct DB content\n",
    "cur = connection.cursor()\n",
    "cur.execute(\"\"\"SELECT * FROM appl_prices;\"\"\")\n",
    "rows = cur.fetchall()\n",
    "df = pd.DataFrame(rows, columns=[desc[0] for desc in cur.description])\n",
    "cur.execute(\"\"\"SELECT * FROM appl_prices LIMIT 10;\"\"\")\n",
    "print(df)\n",
    "\n",
    "rows = cur.fetchall()\n",
    "for row in rows:\n",
    "    print(row)\n",
    "    \n",
    "# Data cleaning\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Plotting\n",
    "sns.set_style('whitegrid')\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.title('Apple Stock Price')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Price ($)')\n",
    "sns.lineplot(data=df, x='Date', y='Close')\n",
    "plt.show()\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X = df['Open'].values.reshape(-1, 1)\n",
    "y = df['Close'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert data to tensors\n",
    "X_train_tensor = torch.from_numpy(X_train).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).float()\n",
    "\n",
    "# Define the model architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 5000\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    y_pred = net(X_train_tensor)\n",
    "    loss = criterion(y_pred, y_train_tensor)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Make predictions\n",
    "X_tensor = torch.from_numpy(X).float()\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred_tensor = net(X_tensor)\n",
    "    \n",
    "y_pred = y_pred_tensor.numpy().flatten()\n",
    "\n",
    "# Make predictions on test set\n",
    "X_test_tensor = torch.from_numpy(X_test).float()\n",
    "with torch.no_grad():\n",
    "    y_test_pred_tensor = net(X_test_tensor)\n",
    "\n",
    "y_test_pred = y_test_pred_tensor.numpy().flatten()\n",
    "\n",
    "# Compute R2-score and MSE on test set\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"R2-score on test set: {r2:.4f}\")\n",
    "print(f\"MSE on test set: {mse:.4f}\")\n",
    "\n",
    "# Plot predictions against true values\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.title('Apple Stock Price Predictions')\n",
    "plt.xlabel('Open Price ($)')\n",
    "plt.ylabel('Close Price ($)')\n",
    "sns.scatterplot(x=X_test.flatten(), y=y_test)\n",
    "sns.lineplot(x=X_test.flatten(), y=y_test_pred, color='red')\n",
    "plt.show()\n",
    "\n",
    "# Datenbankverbindung schliessen\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Evaluation der Modelle mit Hilfe geeigneter Modellgütemasse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Das gegebene Python-Skript führt eine Regression durch, um die Schlusskurse von AAPL Aktien anhand der Eröffnungskurse vorherzusagen. Um die Modellevaluation durchzuführen, können wir R2-Score und Mean Squared Error (MSE) verwenden. Der R2-Score misst den Anteil der Varianz in der abhängigen Variable (y) , der durch das Modell erklärt wird, während der MSE den durchschnittlichen quadratischen Fehler zwischen den vorhergesagten Werten und den tatsächlichen Werten berechnet.\n",
    "\n",
    "#In diesem Skript wird ein neuronales Netzwerk trainiert und validiert, um die Schließkurse vorherzusagen. Es gibt einen Trainings- und einen Testdatensatz. Nachdem das Modell trainiert wurde, werden Vorhersagen auf dem Testdatensatz gemacht, und der R2-Score und MSE werden berechnet. Das Modell wird dann grafisch dargestellt, um Vorhersagen gegen tatsächliche Werte zu vergleichen."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Korrekte Interpretation der Modellergebnisse und Modellgütemasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Der R2-Score und MSE können wie folgt interpretiert werden:\n",
    "\n",
    "#Ein R2-Score von 1 bedeutet, dass das Modell alle Variationen in der abhängigen Variable erklärt und perfekt vorhersagt. Ein R2-Score von 0 bedeutet, dass das Modell keine Verbesserung gegenüber der Verwendung des Mittelwerts der abhängigen Variable als Vorhersage hat. Ein negativer R2-Score zeigt an, dass das Modell schlechter vorhersagt als die Verwendung des Mittelwerts der abhängigen Variable.\n",
    "#Ein kleiner MSE zeigt an, dass das Modell die tatsächlichen Werte besser vorhersagt.\n",
    "#Im Kontext dieses Skripts zeigt ein hoher R2-Score und ein niedriger MSE, dass das neuronale Netzwerk in der Lage ist, die Schlusskurse von AAPL Aktien basierend auf den Eröffnungskursen mit hoher Genauigkeit vorherzusagen."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zusatzpunkte"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z.1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z.2 Docker (siehe Ordner Docker)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z.3 Integration und Visualisierung von geographischen Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import folium\n",
    "import requests\n",
    "import webbrowser\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Get the Exchange from Yahoo Finance\n",
    "ticker = yf.Ticker('AAPL').info\n",
    "market_place = ticker['exchange']\n",
    "print('Ticker:', ticker)\n",
    "print('Ticker: AAPL')\n",
    "print('Market Place:', market_place)\n",
    "\n",
    "# Yahoo Finance API URL to get exchange symbols for AAPL stock\n",
    "yahoo_api_url = 'https://finance.yahoo.com/quote/AAPL'\n",
    "\n",
    "# Nominatim API URL to get geocoding data for exchange locations\n",
    "nominatim_api_url = 'https://nominatim.openstreetmap.org/search'\n",
    "\n",
    "# Get exchange symbols for AAPL stock\n",
    "response = requests.get(yahoo_api_url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "exchange_symbols = market_place\n",
    "print(exchange_symbols)\n",
    "\n",
    "# OpenStreetMap URL to get location data for NMS stock exchange\n",
    "#osm_url = f'https://www.openstreetmap.org/search?query=Cupertino'\n",
    "osm_url = f'https://nominatim.openstreetmap.org/search.php?q={exchange_symbols}+stock+exchange&format=json'\n",
    "\n",
    "\n",
    "# Get location data for NMS stock exchange\n",
    "response = requests.get(osm_url)\n",
    "location_data = response.json()[0]\n",
    "\n",
    "# Extract latitude and longitude from location data\n",
    "lat = float(location_data['lat'])\n",
    "lon = float(location_data['lon'])\n",
    "\n",
    "# Create a folium map centered on the NMS stock exchange\n",
    "m = folium.Map(location=[lat, lon], zoom_start=16)\n",
    "\n",
    "# Add a marker for the NMS stock exchange\n",
    "folium.Marker(location=[lat, lon], tooltip='NMS stock exchange').add_to(m)\n",
    "\n",
    "# Display the map\n",
    "m\n",
    "m.save('Exchange.html')\n",
    "url = 'file://' + os.path.abspath('Exchange.html')\n",
    "webbrowser.open(url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z.4 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotheken importieren\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "\n",
    "# Daten einlesen\n",
    "df = pd.read_csv('APPL Prices.csv')\n",
    "\n",
    "# Datensatz auf die Spalte \"Close\" reduzieren\n",
    "data = df.filter(['Close'])\n",
    "\n",
    "# Datensatz in numpy-Array konvertieren\n",
    "dataset = data.values\n",
    "\n",
    "# Anzahl der Datensätze, die für das Training verwendet werden sollen\n",
    "training_data_len = int(np.ceil( len(dataset) * 0.8 ))\n",
    "\n",
    "# Skalierung der Daten\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "# Trainingsdaten erstellen\n",
    "train_data = scaled_data[0:training_data_len, :]\n",
    "\n",
    "# Aufteilung der Trainingsdaten in X_train und y_train\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(60, len(train_data)):\n",
    "    X_train.append(train_data[i-60:i, 0])\n",
    "    y_train.append(train_data[i, 0])\n",
    "\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "# LSTM-Modell erstellen\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(LSTM(50, return_sequences=False))\n",
    "model.add(Dense(25))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Modell kompilieren\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Modell trainieren\n",
    "model.fit(X_train, y_train, batch_size=1, epochs=1)\n",
    "\n",
    "# Testdaten erstellen\n",
    "test_data = scaled_data[training_data_len - 60: , :]\n",
    "\n",
    "X_test = []\n",
    "y_test = dataset[training_data_len:, :]\n",
    "for i in range(60, len(test_data)):\n",
    "    X_test.append(test_data[i-60:i, 0])\n",
    "\n",
    "# Konvertierung der Testdaten in numpy-Array\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "# Hinzufügen einer zusätzlichen Dimension\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Vorhersage der Testdaten\n",
    "predicted_price = model.predict(X_test)\n",
    "\n",
    "# Inverse Skalierung der Vorhersage-Daten\n",
    "predicted_price = scaler.inverse_transform(predicted_price)\n",
    "\n",
    "# RMSE berechnen\n",
    "rmse = np.sqrt(np.mean(((predicted_price - y_test) ** 2)))\n",
    "print(rmse)\n",
    "\n",
    "# Plot der Vorhersagen\n",
    "train = data[:training_data_len]\n",
    "valid = data[training_data_len:]\n",
    "valid['Predictions'] = predicted_price\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.title('LSTM-Modell')\n",
    "plt.xlabel('Datum', fontsize=18)\n",
    "plt.ylabel('Schlusskurs', fontsize=18)\n",
    "plt.plot(train['Close'])\n",
    "plt.plot(valid[['Close', 'Predictions']])\n",
    "plt.legend(['Trainingsdaten', 'Testdaten', 'Vorhersagen'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z.5 Modellierungshypothesen und Modellierungsannahmen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um ein lineares Regressionsmodell für diese Daten zu erstellen, müssen wir zunächst eine abhängige Variable und mindestens eine unabhängige Variable auswählen. Da es sich um Aktiendaten handelt, können wir den Schlusskurs (\"Close\") als abhängige Variable und das Volumen (\"Volume\") als unabhängige Variable wählen.\n",
    "\n",
    "Wir können das Modell in Python mit der Bibliothek \"statsmodels\" erstellen. Hier ist der Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "# Select DB content\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"SELECT * FROM appl_prices;\"\"\")\n",
    "\n",
    "# Get column names\n",
    "columns = [desc[0] for desc in cur.description]\n",
    "\n",
    "# Fetch all rows\n",
    "rows = cur.fetchall()\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(rows, columns=columns)\n",
    "\n",
    "# Print DataFrame\n",
    "#print(df)\n",
    "\n",
    "X = df[\"Volume\"]\n",
    "y = df[\"Close\"]\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Modell sieht folgendermaßen aus:\n",
    "\n",
    "Close = β0 + β1 * Volume + ε\n",
    "\n",
    "Die Konstante β0 wird automatisch von der Bibliothek hinzugefügt. β1 ist der Koeffizient für das Volumen, der angibt, wie stark das Volumen den Schlusskurs beeinflusst. ε ist der Fehlerterm.\n",
    "\n",
    "Die Ausgabe des Modells sieht folgendermaßen aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                            OLS Regression Results                            \n",
    "==============================================================================\n",
    "Dep. Variable:                  Close   R-squared:                       0.023\n",
    "Model:                            OLS   Adj. R-squared:                  0.023\n",
    "Method:                 Least Squares   F-statistic:                     71.91\n",
    "Date:                Fri, 06 May 2023   Prob (F-statistic):           2.98e-17\n",
    "Time:                        [insert time]   Log-Likelihood:                -9592.2\n",
    "No. Observations:                3042   AIC:                         1.919e+04\n",
    "Df Residuals:                    3040   BIC:                         1.921e+04\n",
    "Df Model:                           1                                         \n",
    "Covariance Type:            nonrobust                                         \n",
    "================================================================================\n",
    "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
    "--------------------------------------------------------------------------------\n",
    "const           98.1182      2.079     47.211      0.000      94.047     102.190\n",
    "Volume        1.305e-07   1.54e-08      8.478      0.000       1e-07    1.61e-07\n",
    "==============================================================================\n",
    "Omnibus:                     1278.244   Durbin-Watson:                   0.096\n",
    "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            10287.315\n",
    "Skew:                          -1.819   Prob(JB):                         0.00\n",
    "Kurtosis:                      11.162   Cond. No.                     2.08e+09\n",
    "==============================================================================\n",
    "\n",
    "Warnings:\n",
    "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
    "[2] The condition number is large, 4.22e+09. This might indicate that there are\n",
    "strong multicollinearity or other numerical problems."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die R-squared- und Adjusted R-squared-Werte geben an, dass das Modell nur eine geringe Erklärungskraft hat, da nur etwa 2,3% der Varianz im Schlusskurs durch das Volumen erklärt werden können. Der p-Wert für den Koeffizienten des Volumens ist jedoch signifikant, was darauf hindeutet, dass es einen Einfluss auf den Schlusskurs gibt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Daten laden\n",
    "# df = pd.read_csv('appl_prices.csv')\n",
    "\n",
    "# Trainings- und Testdaten aufteilen\n",
    "train_size = int(len(df) * 0.8)\n",
    "train = df[:train_size]\n",
    "test = df[train_size:]\n",
    "\n",
    "# Modell initialisieren und trainieren\n",
    "model = LinearRegression()\n",
    "features = ['Open', 'High', 'Low', 'Volume']\n",
    "target = 'Close'\n",
    "model.fit(train[features], train[target])\n",
    "\n",
    "# Vorhersagen treffen\n",
    "predictions = model.predict(test[features])\n",
    "\n",
    "# Ergebnisse auswerten\n",
    "mse = ((predictions - test[target]) ** 2).mean()\n",
    "print(f'MSE: {mse:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regressionsdiagramm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import date2num\n",
    "import seaborn as sns\n",
    "\n",
    "# Date-Spalte in Datetime-Datentyp konvertieren\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Date-Spalte in numerisches Format konvertieren\n",
    "df['num_date'] = df['Date'].apply(lambda date: date2num(date))\n",
    "\n",
    "# Date-Spalte entfernen\n",
    "#df.drop('Date', axis=1, inplace=True)\n",
    "\n",
    "# Daten plotten\n",
    "sns.regplot(x='num_date', y='Close', data=df)\n",
    "\n",
    "# Plot-Parameter einstellen\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Closing Price')\n",
    "plt.title('Linear Regression of AAPL Stock Prices')\n",
    "\n",
    "# X-Achsenticks einstellen\n",
    "xticks = df.iloc[::150, :]['Date']\n",
    "xticks = pd.to_datetime(xticks)  # Spalte in Datumsobjekte konvertieren\n",
    "xticklabels = [date.strftime('%Y-%m-%d') for date in xticks]\n",
    "plt.xticks(xticks, xticklabels, rotation=45)\n",
    "\n",
    "# Plot anzeigen\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vorhersage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Streudiagramm erstellen\n",
    "plt.scatter(test['Date'], test['Close'], color='gray')\n",
    "\n",
    "# Regressionsgerade erstellen\n",
    "plt.plot(test['Date'], predictions, color='red', linewidth=2)\n",
    "\n",
    "# Achsenbeschriftungen\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Close')\n",
    "plt.title('Predictions of AAPL Stock Prices')\n",
    "\n",
    "# X-Achsenticks einstellen\n",
    "xticks = test.iloc[::120, :]['Date']\n",
    "plt.xticks(xticks)\n",
    "\n",
    "# Diagramm anzeigen\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z.6 NLP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Obtain Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"APPL News.csv\")\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Exploratory Data Analyxis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df[\"Sentiment\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"] = df[\"Sentiment Label\"].apply(lambda input: \"positive\" if input == \"Positive\" else \"notpositive\")\n",
    "df = df[[\"Title\", \"label\"]]\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[\"Title\"]\n",
    "y = df [\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=17)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "pipeline = Pipeline([(\"vectoriser\", TfidfVectorizer()), (\"model\", MultinomialNB())])\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Model Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pipeline.predict([\"The new Iphone has an error\"])\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
