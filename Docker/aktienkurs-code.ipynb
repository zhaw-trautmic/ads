{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Datenerhebung mittels API & Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "#sns.get_dataset_names()\n",
    "from pandas_datareader import data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Yahoo Finance API: Aktienkurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date        Open        High         Low       Close   Adj Close  \\\n",
      "0     2010-01-04    7.622500    7.660714    7.585000    7.643214    6.505280   \n",
      "1     2010-01-05    7.664286    7.699643    7.616071    7.656429    6.516526   \n",
      "2     2010-01-06    7.656429    7.686786    7.526786    7.534643    6.412873   \n",
      "3     2010-01-07    7.562500    7.571429    7.466071    7.520714    6.401016   \n",
      "4     2010-01-08    7.510714    7.571429    7.466429    7.570714    6.443575   \n",
      "...          ...         ...         ...         ...         ...         ...   \n",
      "3037  2022-01-26  163.500000  164.389999  157.820007  159.690002  158.526489   \n",
      "3038  2022-01-27  162.449997  163.839996  158.279999  159.220001  158.059906   \n",
      "3039  2022-01-28  165.710007  170.350006  162.800003  170.330002  169.088974   \n",
      "3040  2022-01-31  170.160004  175.000000  169.509995  174.779999  173.506546   \n",
      "3041  2022-02-01  174.009995  174.839996  172.309998  174.610001  173.337799   \n",
      "\n",
      "         Volume  \n",
      "0     493729600  \n",
      "1     601904800  \n",
      "2     552160000  \n",
      "3     477131200  \n",
      "4     447610800  \n",
      "...         ...  \n",
      "3037  108275300  \n",
      "3038  121954600  \n",
      "3039  179935700  \n",
      "3040  115541600  \n",
      "3041   86213900  \n",
      "\n",
      "[3042 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "ticker = 'AAPL'\n",
    "period1 = int(time.mktime(datetime.datetime(2010, 1, 1, 23, 59).timetuple()))\n",
    "period2 = int(time.mktime(datetime.datetime(2022, 2, 1, 23, 59).timetuple()))\n",
    "interval = '1d'\n",
    "query_string = f'https://query1.finance.yahoo.com/v7/finance/download/{ticker}?period1={period1}&period2={period2}&interval={interval}&events=history&includeAdjustedClose=true'\n",
    "data = pd.read_csv(query_string)\n",
    "print(data)\n",
    "data.to_csv('APPL Prices.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response.ok : False , response.status_code : 404\n",
      "Preview of response.text :  <!DOCTYPE html>\n",
      "  <html lang=\"en-us\"><head>\n",
      "  <meta http-equiv=\"content-type\" content=\"text/html; charset=UTF-8\">\n",
      "      <meta charset=\"utf-8\">\n",
      "      <title>Yahoo</title>\n",
      "      <meta name=\"viewport\" content=\"width=device-width,initial-scale=1,minimal-ui\">\n",
      "      <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\">\n",
      "      <style>\n",
      "  html {\n",
      "      height: 100%;\n",
      "  }\n",
      "  body {\n",
      "      background: #fafafc url(https://s.yimg.com/nn/img/sad-panda-201402200631.png) 50% 50%;\n",
      "      background-size: cove\n"
     ]
    }
   ],
   "source": [
    "# import modules\n",
    "import os \n",
    "import requests \n",
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#get the URL using response variable \n",
    "my_url = \"https://finance.yahoo.com/quote/AAPL/community?p=AAPL\" \n",
    "response = requests.get(my_url)\n",
    "\n",
    "#Catching Exceptions \n",
    "print(\"response.ok : {} , response.status_code : {}\".format(response.ok , response.status_code)) \n",
    "print(\"Preview of response.text : \", response.text[:500])\n",
    "\n",
    "\n",
    "###########################\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# die URL der Webseite, die gescraped werden soll\n",
    "url = \"https://www.cash.ch/news/top-news\"\n",
    "\n",
    "# die HTML-Seite herunterladen\n",
    "response = requests.get(url)\n",
    "\n",
    "# eine BeautifulSoup-Instanz erstellen\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# alle Schlagzeilen auf der Seite auswÃ¤hlen\n",
    "headlines = soup.find_all(\"h2\", {\"class\": \"media-heading\"})\n",
    "\n",
    "# alle Schlagzeilen ausgeben\n",
    "for headline in headlines:\n",
    "    print(headline.text.strip())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Datenaufbereitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entfernen NAs und Duplikate, Erstellen neuer Variablen, Anreicherung der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning --> Hier noch mehr Befehle suchen\n",
    "\n",
    "df = data.drop_duplicates()\n",
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 DB - Postgres DB initiate -> In Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os\n",
    "import fnmatch\n",
    "import tempfile\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "os.environ['MPLCONFIGDIR'] = \"/home/jovyan\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Settings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DB Connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "could not translate host name \"db\" to address: Unknown host\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m conn \u001b[39m=\u001b[39m psycopg2\u001b[39m.\u001b[39;49mconnect(\u001b[39m\"\u001b[39;49m\u001b[39mhost=db dbname=postgres user=admin password=secret\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\TRAUTMANN\\.conda\\envs\\adsenv\\lib\\site-packages\\psycopg2\\__init__.py:122\u001b[0m, in \u001b[0;36mconnect\u001b[1;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     kwasync[\u001b[39m'\u001b[39m\u001b[39masync_\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39masync_\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    121\u001b[0m dsn \u001b[39m=\u001b[39m _ext\u001b[39m.\u001b[39mmake_dsn(dsn, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 122\u001b[0m conn \u001b[39m=\u001b[39m _connect(dsn, connection_factory\u001b[39m=\u001b[39mconnection_factory, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwasync)\n\u001b[0;32m    123\u001b[0m \u001b[39mif\u001b[39;00m cursor_factory \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     conn\u001b[39m.\u001b[39mcursor_factory \u001b[39m=\u001b[39m cursor_factory\n",
      "\u001b[1;31mOperationalError\u001b[0m: could not translate host name \"db\" to address: Unknown host\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(\"host=db dbname=postgres user=admin password=secret\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 DB Insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://admin:secret@db:5432/postgres')\n",
    "data.to_sql('appl_prices', engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 SQL Abfrage Select *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.read_sql_query('''SELECT\n",
    "                             *\n",
    "                             FROM appl_prices''', \n",
    "                          con=engine)\n",
    "df_sub.head()\n",
    "df_sub.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Daten aus DB lesen und bearbeiten\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas_datareader import data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Exploratory data analysis\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "\n",
    "# Plotting\n",
    "sns.set_style('whitegrid')\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.title('Apple Stock Price')\n",
    "plt.xlabel('Year')\n",
    "\n",
    "plt.ylabel('Price ($)')\n",
    "sns.lineplot(data=df, x='Date', y='Close')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.title('Daily Change in Apple Stock Price')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Change in price ($)')\n",
    "sns.lineplot(data=df, x='Date', y='Close').set(ylabel='Price ($)', xlabel='Year')\n",
    "sns.lineplot(data=df, x='Date', y=df['Close'].diff()).set(ylabel='Change in price ($)', xlabel='Year')\n",
    "plt.legend(labels=['Price', 'Daily Change'])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.title('Apple Stock Price Distribution')\n",
    "sns.histplot(data=df, x='Close', bins=30)\n",
    "plt.show()\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X = df['Open'].values.reshape(-1, 1)\n",
    "y = df['Close'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'R-squared: {r2:.2f}')\n",
    "print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. ML Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z.3 Integration und Visualisierung von geographischen Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import folium\n",
    "import requests\n",
    "import webbrowser\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Get the Exchange from Yahoo Finance\n",
    "ticker = yf.Ticker('AAPL').info\n",
    "market_place = ticker['exchange']\n",
    "print('Ticker:', ticker)\n",
    "print('Ticker: AAPL')\n",
    "print('Market Place:', market_place)\n",
    "\n",
    "# Yahoo Finance API URL to get exchange symbols for AAPL stock\n",
    "yahoo_api_url = 'https://finance.yahoo.com/quote/AAPL'\n",
    "\n",
    "# Nominatim API URL to get geocoding data for exchange locations\n",
    "nominatim_api_url = 'https://nominatim.openstreetmap.org/search'\n",
    "\n",
    "# Get exchange symbols for AAPL stock\n",
    "response = requests.get(yahoo_api_url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "exchange_symbols = market_place\n",
    "print(exchange_symbols)\n",
    "\n",
    "# OpenStreetMap URL to get location data for NMS stock exchange\n",
    "osm_url = f'https://nominatim.openstreetmap.org/search.php?q={exchange_symbols}+stock+exchange&format=json'\n",
    "\n",
    "# Get location data for NMS stock exchange\n",
    "response = requests.get(osm_url)\n",
    "location_data = response.json()[0]\n",
    "\n",
    "# Extract latitude and longitude from location data\n",
    "lat = float(location_data['lat'])\n",
    "lon = float(location_data['lon'])\n",
    "\n",
    "# Create a folium map centered on the NMS stock exchange\n",
    "m = folium.Map(location=[lat, lon], zoom_start=16)\n",
    "\n",
    "# Add a marker for the NMS stock exchange\n",
    "folium.Marker(location=[lat, lon], tooltip='NMS stock exchange').add_to(m)\n",
    "\n",
    "# Display the map\n",
    "m\n",
    "m.save('Exchange.html')\n",
    "url = 'file://' + os.path.abspath('Exchange.html')\n",
    "webbrowser.open(url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
